{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47565e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5d50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#print the pytorch version\n",
    "# device = torch.cuda.is_available()\n",
    "device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device, torch.__version__\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    \n",
    "print(train_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea2f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    \n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8948390",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6a03bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inp = model.fc.in_features\n",
    "model.fc = nn.Linear(num_inp, 5)\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad6b5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#only train the classifier part, the features part are frozen\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=0.015, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd92ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7f6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO UNFREEZE THE WEIGHTS FOR THE SECOND TIME TRAINING AND DON'T FORGET TO CHANGE THE OPTIMIZER TOO!\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# train the WHOLE part instead of just the classifier!, THIS IS THE SECOND ITERATION OF THE TRAINING AND REDUCE THE LEARNING RATE TOO!\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0002, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f88a4337",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_cifar_resnet152.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ac1775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "test_dir = data_dir + '/valid'\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a570aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels =dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acda7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('0', '1', '2', '3', '4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44bc3cf2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ec9a18c88876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(250)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0a5da9980432>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(inp, title)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# PyTorch tensors assume the color channel is the first dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# but matplotlib assumes is the third dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Undo preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8b62f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = model(images)\n",
    "_, pred = torch.max(outputs, 1)\n",
    "#print('Predicted: ', ' '.join('%5s' % classes[pred[j]] for j in range(250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52fb6fca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for j in range(250):\n",
    "    print(classes[pred[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f12ab97",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"./dataset/valid/valid/10_13_20211119093410011.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211119093410088.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211119093410165.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211119161549009.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549042.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549072.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549093.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549114.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549135.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549162.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549183.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549213.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211119161549237.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_13_20211122043639009.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211122043639108.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211122043639196.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211123044420030.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211123044420107.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_13_20211123044420184.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211119093626018.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211119093626095.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211119093626172.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211122043900006.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211122043900083.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211122043900160.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211122043900237.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211123044650070.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211123044650147.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_14_20211123044650224.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_15_20211119093847058.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_15_20211119093847135.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_15_20211119093847212.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_15_20211122044136015.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136039.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136063.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136096.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136120.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136141.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136162.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136192.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211122044136216.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929000.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929027.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929048.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929075.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929099.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929126.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929147.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929171.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929195.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_15_20211123044929222.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_16_20211119094105046.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211119094105123.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211119094105200.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211122095507034.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211122095507111.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211122095507188.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211123094616022.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211123094616099.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_16_20211123094616176.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211119094323010.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211119094323087.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211119094323164.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211119094323241.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211122095727075.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211122095727152.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211122095727229.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211123094840063.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211123094840140.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_17_20211123094840217.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_18_20211119094535051.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_18_20211119094535128.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_18_20211119094535205.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_18_20211122095953000.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953021.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953045.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953069.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953096.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953117.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953138.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953159.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953183.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953213.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211122095953234.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101012.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101033.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101054.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101087.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101108.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101129.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101150.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101171.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101198.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_18_20211123095101219.jpg\": 1,\n",
      "\"./dataset/valid/valid/10_19_20211119160500039.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_19_20211119160500116.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_19_20211119160500193.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_1_20211119094923006.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923033.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923057.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923078.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923099.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923126.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923150.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923174.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923198.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211119094923225.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_1_20211122044402012.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211122044402056.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211122044402104.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211122044402132.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211122044402180.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211122044402220.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211123095324008.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211123095324056.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211123095324088.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211123095324124.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211123095324160.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211123095324196.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_1_20211123095324224.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_20_20211119160717027.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_20_20211119160717104.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_20_20211119160717181.jpg\": 0,\n",
      "\"./dataset/valid/valid/10_2_20211119095143006.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143036.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143063.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143087.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143111.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143135.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143159.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143186.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143207.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211119095143234.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_2_20211122044724006.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211122044724048.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211122044724102.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211122044724144.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211122044724192.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211122044724234.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211123095638033.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211123095638081.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211123095638123.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211123095638165.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_2_20211123095638207.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_3_20211119095407019.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407046.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407067.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407091.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407118.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407142.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407163.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407190.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407211.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211119095407238.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_3_20211122045011009.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211122045011045.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211122045011081.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211122045011109.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211122045011137.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211122045011173.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211122045011209.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211122045011237.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_3_20211123095937017.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_3_20211123095937059.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_3_20211123095937101.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_3_20211123095937143.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_3_20211123095937191.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_3_20211123095937233.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211119095634015.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634042.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634063.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634087.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634111.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634132.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634159.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634180.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634207.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211119095634228.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_4_20211122045322032.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211122045322074.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211122045322116.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211122045322164.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211122045322206.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211123100157005.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211123100157047.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211123100157089.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211123100157137.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211123100157179.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_4_20211123100157221.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_5_20211119095859009.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859033.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859054.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859075.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859102.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859123.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859150.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859171.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859195.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211119095859222.jpg\": 2,\n",
      "\"./dataset/valid/valid/10_5_20211122100252026.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_5_20211122100252058.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_5_20211122100252090.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_5_20211122100252122.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_5_20211122100252154.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_5_20211122100252186.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_5_20211122100252214.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935011.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935043.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935071.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935107.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935139.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935171.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935199.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211119160935227.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_6_20211122100639020.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_6_20211122100639068.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_6_20211122100639110.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_6_20211122100639152.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_6_20211122100639200.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_6_20211122100639242.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_7_20211119161209028.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211119161209056.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211119161209084.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211119161209128.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211119161209156.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211119161209184.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211119161209216.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211122100859009.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211122100859041.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211122100859073.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211122100859105.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211122100859145.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211122100859177.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_7_20211122100859217.jpg\": 4,\n",
      "\"./dataset/valid/valid/10_8_20211119161814041.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211119161814083.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211119161814125.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211119161814173.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211119161814215.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211122101139014.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211122101139056.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211122101139098.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211122101139146.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211122101139188.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_8_20211122101139230.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_9_20211119162056035.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_9_20211119162056077.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_9_20211119162056119.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_9_20211119162056161.jpg\": 3,\n",
      "\"./dataset/valid/valid/10_9_20211119162056203.jpg\": 3,\n"
     ]
    }
   ],
   "source": [
    "allFiles, _ = map(list, zip(*test_loader.dataset.samples))\n",
    "for i, (inputs, labels) in enumerate(test_loader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    _, pred = torch.max(outputs.data, 1)\n",
    "    for j in range(inputs.size()[0]):\n",
    "        print('\"'+allFiles[ i * len(test_data) + j ] + '\": ' + classes[pred[j]]+',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
